{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33284789",
   "metadata": {},
   "source": [
    "# EE782 - Programming Assignment 2: AI Guard Agent\n",
    "\n",
    "**Group Members:** Your Name, Your Partner's Name\n",
    "\n",
    "This notebook presents a complete implementation of the AI Guard Agent. The system uses vision, speech, and language models to monitor a room, recognize trusted individuals, and interact with unrecognized persons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91b8d6",
   "metadata": {},
   "source": [
    "### Activation and Basic Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b68846",
   "metadata": {},
   "source": [
    "#### 1. Trusted User Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c47dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STRETCH GOAL] Starting face enrollment and classifier training...\n",
      "[SUCCESS] Processed kshitiz_yadav.png for person: kshitiz\n",
      "[SUCCESS] Processed naresh_1.png for person: naresh\n",
      "[SUCCESS] Processed naresh_10.png for person: naresh\n",
      "[SUCCESS] Processed naresh_11.png for person: naresh\n",
      "[SUCCESS] Processed naresh_12.png for person: naresh\n",
      "[SUCCESS] Processed naresh_2.png for person: naresh\n",
      "[SUCCESS] Processed naresh_3.png for person: naresh\n",
      "[SUCCESS] Processed naresh_4.png for person: naresh\n",
      "[SUCCESS] Processed naresh_5.png for person: naresh\n",
      "[SUCCESS] Processed naresh_6.png for person: naresh\n",
      "[SUCCESS] Processed naresh_7.png for person: naresh\n",
      "[SUCCESS] Processed naresh_8.png for person: naresh\n",
      "[SUCCESS] Processed naresh_9.png for person: naresh\n",
      "[SUCCESS] Processed saarthak_1.png for person: saarthak\n",
      "[SUCCESS] Processed saarthak_2.png for person: saarthak\n",
      "\n",
      "[INFO] Found 15 faces for 3 people. Training SVM classifier...\n",
      "[INFO] Classifier training complete.\n",
      "[INFO] Saved trained model to known_faces_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "TRUSTED_FACES_DIR = \"D:/AI_Guard_Agent/trusted_faces\"\n",
    "MODEL_FILE = \"known_faces_model.pkl\"\n",
    "\n",
    "print(\"[STRETCH GOAL] Starting face enrollment and classifier training...\")\n",
    "known_encodings = []\n",
    "known_names = []\n",
    "\n",
    "if not os.path.exists(TRUSTED_FACES_DIR):\n",
    "    os.makedirs(TRUSTED_FACES_DIR)\n",
    "    print(f\"[WARNING] Created '{TRUSTED_FACES_DIR}' directory. Please add images and run again.\")\n",
    "else:\n",
    "    for filename in os.listdir(TRUSTED_FACES_DIR):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                image_path = os.path.join(TRUSTED_FACES_DIR, filename)\n",
    "                \n",
    "                # --- NEW LOGIC TO PARSE NAMES ---\n",
    "                # Extracts the name from 'name_1.jpg' as 'name'\n",
    "                name = os.path.splitext(filename)[0].split('_')[0]\n",
    "                # --------------------------------\n",
    "\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_encodings = face_recognition.face_encodings(image)\n",
    "                \n",
    "                if face_encodings:\n",
    "                    known_encodings.append(face_encodings[0])\n",
    "                    known_names.append(name)\n",
    "                    print(f\"[SUCCESS] Processed {filename} for person: {name}\")\n",
    "                else:\n",
    "                    print(f\"[WARNING] No face found in {filename}. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Could not process {filename}: {e}\")\n",
    "\n",
    "    if len(np.unique(known_names)) < 2:\n",
    "        print(\"\\n[ERROR] Classifier training requires at least two different people.\")\n",
    "        print(\"Please add images for at least one more person and run again.\")\n",
    "    elif known_encodings:\n",
    "        print(f\"\\n[INFO] Found {len(known_encodings)} faces for {len(np.unique(known_names))} people. Training SVM classifier...\")\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        labels = label_encoder.fit_transform(known_names)\n",
    "        \n",
    "        # Train the SVM classifier\n",
    "        classifier = SVC(gamma=\"scale\", probability=True)\n",
    "        classifier.fit(known_encodings, labels)\n",
    "        print(\"[INFO] Classifier training complete.\")\n",
    "        \n",
    "        # Save the trained model\n",
    "        with open(MODEL_FILE, \"wb\") as f:\n",
    "            pickle.dump({\"classifier\": classifier, \"label_encoder\": label_encoder}, f)\n",
    "        print(f\"[INFO] Saved trained model to {MODEL_FILE}\")\n",
    "    else:\n",
    "        print(\"[INFO] No faces were enrolled.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b2c46",
   "metadata": {},
   "source": [
    "#### Text-to-Speech Module (Testing Speaker Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a18db9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TTS DEMO]: Attempting to say: 'This is a test of the text to speech system.'\n",
      "[SUCCESS] TTS function executed successfully.\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "def test_speak(text):\n",
    "    \"\"\"A standalone function to test the Text-to-Speech (TTS) module.\"\"\"\n",
    "    print(f\"[TTS DEMO]: Attempting to say: '{text}'\")\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang='en')\n",
    "        # Use the system's temporary directory to avoid permission errors\n",
    "        temp_dir = tempfile.gettempdir()\n",
    "        audio_file = os.path.join(temp_dir, \"tts_test.mp3\")\n",
    "        \n",
    "        tts.save(audio_file)\n",
    "        playsound(audio_file)\n",
    "        os.remove(audio_file)\n",
    "        print(\"[SUCCESS] TTS function executed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] TTS failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_speak(\"This is a test of the text to speech system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54621a10",
   "metadata": {},
   "source": [
    "#### 2. Speech Recognition (ASR) + Text-to-Speech (TTS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3998b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AI Guard System Initialized. Calibrating microphone...\n",
      "[INFO] Microphone calibrated. Say 'guard my room' to activate.\n",
      "[INFO] Listening for command...\n",
      "[USER SAID]: guard my room\n",
      "[GUARD SAYS]: Guard mode activated. I will protect this room.\n",
      "[INFO] Listening for command...\n",
      "[USER SAID]: stand down you fucking idiot\n",
      "[GUARD SAYS]: Guard mode deactivated.\n",
      "[INFO] Listening for command...\n",
      "[INFO] Could not understand the audio.\n",
      "[INFO] Listening for command...\n",
      "\n",
      "[INFO] Program interrupted by user. Shutting down.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "# --- Configuration ---\n",
    "ACTIVATION_COMMAND = \"guard my room\"\n",
    "DEACTIVATION_COMMAND = \"stand down\"\n",
    "\n",
    "class AI_Guard:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the AI Guard System.\"\"\"\n",
    "        self.guard_mode_active = False\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.microphone = sr.Microphone()\n",
    "        \n",
    "        print(\"[INFO] AI Guard System Initialized. Calibrating microphone...\")\n",
    "        with self.microphone as source:\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "        print(\"[INFO] Microphone calibrated. Say 'guard my room' to activate.\")\n",
    "\n",
    "    def speak(self, text):\n",
    "        \"\"\"Converts text to speech using gTTS and plays it.\"\"\"\n",
    "        print(f\"[GUARD SAYS]: {text}\")\n",
    "        try:\n",
    "            tts = gTTS(text=text, lang='en')\n",
    "            # Use the system's temporary directory to avoid permission errors\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            audio_file = os.path.join(temp_dir, \"response.mp3\")\n",
    "            tts.save(audio_file)\n",
    "            playsound(audio_file)\n",
    "            os.remove(audio_file)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not speak due to an error: {e}\")\n",
    "\n",
    "    def listen_for_command(self):\n",
    "        \"\"\"Listens for a command from the user and converts it to text.\"\"\"\n",
    "        command = \"\"\n",
    "        try:\n",
    "            with self.microphone as source:\n",
    "                print(\"[INFO] Listening for command...\")\n",
    "                audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=3)\n",
    "            command = self.recognizer.recognize_google(audio).lower()\n",
    "            print(f\"[USER SAID]: {command}\")\n",
    "        except sr.WaitTimeoutError:\n",
    "            pass \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"[INFO] Could not understand the audio.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"[ERROR] Could not request results from Google Speech Recognition service; {e}\")\n",
    "        return command\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop for the AI Guard with graceful shutdown.\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                command = self.listen_for_command()\n",
    "\n",
    "                if self.guard_mode_active:\n",
    "                    if DEACTIVATION_COMMAND in command:\n",
    "                        self.guard_mode_active = False\n",
    "                        self.speak(\"Guard mode deactivated.\")\n",
    "                    else:\n",
    "                        print(\"[STATUS] Guard mode is active. Monitoring...\")\n",
    "                else:\n",
    "                    if ACTIVATION_COMMAND in command:\n",
    "                        self.guard_mode_active = True\n",
    "                        self.speak(\"Guard mode activated. I will protect this room.\")\n",
    "\n",
    "                time.sleep(1) # Small delay to prevent high CPU usage\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n[INFO] Program interrupted by user. Shutting down.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    guard = AI_Guard()\n",
    "    guard.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a3a6f",
   "metadata": {},
   "source": [
    "### Face Recognition and Verify Trusted User Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AI Guard System Initialized. Calibrating microphone...\n",
      "[INFO] Microphone calibrated.\n",
      "[INFO] Loaded trained face recognition model.\n",
      "\n",
      "[INFO] AI Guard is running. System is now listening for activation commands.\n",
      "[INFO] Listening for a command...\n",
      "[USER SAID]: guard my room\n",
      "[GUARD SAYS]: Guard mode activated. Vision system online.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[GUARD SAYS]: Warning. An unrecognized person has been detected.\n",
      "[ERROR] Could not speak due to an error: No such file or directory: 'C:\\Users\\nares\\AppData\\Local\\Temp\\response.mp3'.\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.77\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[USER SAID]: warning and unrecognized[DEBUG] Predicted: naresh, Confidence: 0.78\n",
      "\n",
      "[INFO] Listening for a command...[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[GUARD SAYS]: Warning. An unrecognized person has been detected.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82[USER SAID]: an unrecognized\n",
      "\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.77\n",
      "[GUARD SAYS]: Warning. An unrecognized person has been detected.\n",
      "[USER SAID]: birthday\n",
      "[INFO] Listening for a command...\n",
      "[USER SAID]: an unrecognized\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82[INFO] Listening for a command...\n",
      "\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.78\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.77\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.78\n",
      "[GUARD SAYS]: Warning. An unrecognized person has been detected.\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[GUARD SAYS]: Warning. An unrecognized person has been detected.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[USER SAID]: warning an unrecognized\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[GUARD SAYS]: Warning. An unrecognized person has been detected.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.85\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.85\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "\n",
      "[INFO] Program interrupted by user. Shutting down.\n",
      "[USER SAID]: morning and unrecognized person has been detected\n",
      "[INFO] Webcam released and all windows closed.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tempfile\n",
    "import threading\n",
    "import pygame # Import the pygame library\n",
    "\n",
    "# --- Configuration ---\n",
    "ACTIVATION_COMMAND = \"guard my room\"\n",
    "DEACTIVATION_COMMAND = \"stand down\"\n",
    "MODEL_FILE = \"known_faces_model.pkl\"\n",
    "RECOGNITION_THRESHOLD = 0.75\n",
    "\n",
    "\n",
    "# --- Base Class Definition (UPDATED with Pygame) ---\n",
    "class AI_Guard:\n",
    "    def __init__(self):\n",
    "        self.guard_mode_active = False\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.microphone = sr.Microphone()\n",
    "        \n",
    "        # --- NEW: Initialize the Pygame mixer for audio playback ---\n",
    "        pygame.mixer.init()\n",
    "        # --------------------------------------------------------\n",
    "\n",
    "        print(\"[INFO] AI Guard System Initialized. Calibrating microphone...\")\n",
    "        with self.microphone as source:\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "        print(\"[INFO] Microphone calibrated.\")\n",
    "\n",
    "    def speak(self, text):\n",
    "        \"\"\"Converts text to speech using gTTS and plays it with Pygame.\"\"\"\n",
    "        print(f\"[GUARD SAYS]: {text}\")\n",
    "        try:\n",
    "            tts = gTTS(text=text, lang='en')\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            audio_file = os.path.join(temp_dir, \"response.mp3\")\n",
    "            tts.save(audio_file)\n",
    "\n",
    "            # --- NEW: Use Pygame to load and play the audio ---\n",
    "            pygame.mixer.music.load(audio_file)\n",
    "            pygame.mixer.music.play()\n",
    "            while pygame.mixer.music.get_busy():\n",
    "                time.sleep(0.1)\n",
    "            pygame.mixer.music.unload() # Unload the file to allow deletion\n",
    "            # ------------------------------------------------\n",
    "\n",
    "            os.remove(audio_file)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not speak due to an error: {e}\")\n",
    "\n",
    "    def listen_for_command(self):\n",
    "        command = \"\"\n",
    "        try:\n",
    "            with self.microphone as source:\n",
    "                print(\"[INFO] Listening for a command...\")\n",
    "                audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=4)\n",
    "            command = self.recognizer.recognize_google(audio).lower()\n",
    "            print(f\"[USER SAID]: {command}\")\n",
    "        except (sr.WaitTimeoutError, sr.UnknownValueError, sr.RequestError):\n",
    "            pass\n",
    "        return command\n",
    "\n",
    "\n",
    "# --- Vision Class (No changes needed in this class) ---\n",
    "class AI_Guard_Vision(AI_Guard):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            with open(MODEL_FILE, \"rb\") as f:\n",
    "                self.model_data = pickle.load(f)\n",
    "            print(\"[INFO] Loaded trained face recognition model.\")\n",
    "        except FileNotFoundError:\n",
    "            self.speak(f\"Error: Model file '{MODEL_FILE}' not found. Please run the enrollment script first.\")\n",
    "            exit()\n",
    "            \n",
    "        self.video_capture = cv2.VideoCapture(0)\n",
    "        if not self.video_capture.isOpened():\n",
    "            self.speak(\"Error: Cannot open webcam.\")\n",
    "            exit()\n",
    "            \n",
    "        self.last_seen_trusted_time = 0\n",
    "        self.last_unrecognized_alert_time = 0\n",
    "        self.cooldown_period = 10\n",
    "        self.stop_event = threading.Event()\n",
    "        self.vision_window_active = False\n",
    "\n",
    "    def process_vision(self):\n",
    "        ret, frame = self.video_capture.read()\n",
    "        if not ret: return\n",
    "\n",
    "        rgb_small_frame = cv2.cvtColor(cv2.resize(frame, (0, 0), fx=0.25, fy=0.25), cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        is_any_person_present = len(face_encodings) > 0\n",
    "        found_trusted_person = False\n",
    "\n",
    "        classifier = self.model_data[\"classifier\"]\n",
    "        label_encoder = self.model_data[\"label_encoder\"]\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            probabilities = classifier.predict_proba([face_encoding])[0]\n",
    "            best_match_index = np.argmax(probabilities)\n",
    "            predicted_name = label_encoder.classes_[best_match_index]\n",
    "            confidence = probabilities[best_match_index]\n",
    "            \n",
    "            print(f\"[DEBUG] Predicted: {predicted_name}, Confidence: {confidence:.2f}\")\n",
    "            \n",
    "            display_name = \"Unrecognized\"\n",
    "            if confidence > RECOGNITION_THRESHOLD:\n",
    "                found_trusted_person = True\n",
    "                display_name = predicted_name.replace('_', ' ')\n",
    "                \n",
    "                current_time = time.time()\n",
    "                if current_time - self.last_seen_trusted_time > self.cooldown_period:\n",
    "                    self.speak(f\"Welcome, {display_name}. Glad to see you.\")\n",
    "                    self.last_seen_trusted_time = current_time\n",
    "\n",
    "            top *= 4; right *= 4; bottom *= 4; left *= 4\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            label = f\"{display_name} ({confidence:.2f})\"\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, label, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 1)\n",
    "\n",
    "        if not found_trusted_person and is_any_person_present:\n",
    "            current_time = time.time()\n",
    "            if current_time - self.last_unrecognized_alert_time > self.cooldown_period:\n",
    "                self.speak(\"Warning. An unrecognized person has been detected.\")\n",
    "                self.last_unrecognized_alert_time = current_time\n",
    "        \n",
    "        cv2.imshow('AI Guard Vision', frame)\n",
    "        self.vision_window_active = True\n",
    "\n",
    "    def _threaded_listener(self):\n",
    "        while not self.stop_event.is_set():\n",
    "            command = self.listen_for_command()\n",
    "            if ACTIVATION_COMMAND in command and not self.guard_mode_active:\n",
    "                self.guard_mode_active = True\n",
    "                self.speak(\"Guard mode activated. Vision system online.\")\n",
    "            elif DEACTIVATION_COMMAND in command and self.guard_mode_active:\n",
    "                self.guard_mode_active = False\n",
    "                self.speak(\"Guard mode deactivated. Vision system offline.\")\n",
    "\n",
    "    def run(self):\n",
    "        self.stop_event.clear()\n",
    "        listener_thread = threading.Thread(target=self._threaded_listener, daemon=True)\n",
    "        listener_thread.start()\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\n[INFO] AI Guard is running. System is now listening for activation commands.\")\n",
    "            while not self.stop_event.is_set():\n",
    "                if self.guard_mode_active:\n",
    "                    self.process_vision()\n",
    "                else:\n",
    "                    if self.vision_window_active:\n",
    "                        cv2.destroyWindow('AI Guard Vision')\n",
    "                        self.vision_window_active = False\n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    print(\"\\n[INFO] 'q' key pressed. Shutting down.\")\n",
    "                    break\n",
    "                \n",
    "                time.sleep(0.05 if self.guard_mode_active else 0.5)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n[INFO] Program interrupted by user. Shutting down.\")\n",
    "        finally:\n",
    "            self.stop_event.set()\n",
    "            listener_thread.join(timeout=1.0)\n",
    "            self.video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"[INFO] Webcam released and all windows closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    guard = AI_Guard_Vision()\n",
    "    guard.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18736978",
   "metadata": {},
   "source": [
    "### Escalation Dialogue and Full System Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb846ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Groq client configured successfully.\n",
      "[INFO] AI Guard System Initialized. Calibrating microphone...\n",
      "[INFO] Microphone calibrated.\n",
      "[INFO] Loaded trained face recognition model.\n",
      "\n",
      "[INFO] AI Guard is running. Say 'guard my room' to activate.\n",
      "[INFO] Listening for a command...\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[USER SAID]: guard my room\n",
      "[GUARD SAYS]: Guard mode activated. Monitoring the room.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[GUARD SAYS]: Welcome back, naresh.\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.73\n",
      "[ALERT] Intruder detected for the first time.\n",
      "[INFO] Generating Groq response for escalation level 1...\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[GUARD SAYS]: Hi there, can I help you - are you a resident of this room or looking for someone in particular?\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[INFO] Listening for a command...\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[USER SAID]: tiger can i help\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[INFO] Threat cleared. Resetting intruder state.\n",
      "[GUARD SAYS]: Welcome back, naresh.\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[USER SAID]: i'm looking for someone in particular\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.76\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[INFO] Listening for a command...[DEBUG] Predicted: naresh, Confidence: 0.72\n",
      "[ALERT] Intruder detected for the first time.\n",
      "[INFO] Generating Groq response for escalation level 1...\n",
      "\n",
      "[GUARD SAYS]: Hi there, can I help you, are you looking for one of our residents or is there something else I can assist you with?\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[INFO] Listening for a command...\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[INFO] Google Speech Recognition could not understand audio.[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[INFO] Threat cleared. Resetting intruder state.\n",
      "[GUARD SAYS]: Welcome back, naresh.\n",
      "\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84[INFO] Listening for a command...\n",
      "\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[GUARD SAYS]: Welcome back, naresh.\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83[INFO] Listening for a command...\n",
      "\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[GUARD SAYS]: Welcome back, naresh.\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[INFO] Listening for a command...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[INFO] Listening for a command...[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.78\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.77\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.79\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.80\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[INFO] Google Speech Recognition could not understand audio.\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[INFO] Listening for a command...[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[GUARD SAYS]: Welcome back, naresh.\n",
      "\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.81\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.83\n",
      "[INFO] Transcribing with Google Speech Recognition...\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.84\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "[DEBUG] Predicted: naresh, Confidence: 0.82\n",
      "\n",
      "[INFO] Program interrupted by user (Ctrl+C). Shutting down.\n",
      "[USER SAID]: phone number to rest\n",
      "[INFO] System resources released. Shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for all system functionalities\n",
    "import speech_recognition as sr  # For converting speech to text (ASR)\n",
    "from gtts import gTTS             # Google Text-to-Speech for generating audio from text\n",
    "import os                         # For interacting with the operating system (e.g., file deletion)\n",
    "import cv2                        # OpenCV for camera access and image processing\n",
    "import face_recognition           # For finding and encoding faces in images\n",
    "import numpy as np                # For numerical operations, especially with face recognition arrays\n",
    "import pickle                     # For loading the pre-trained face recognition model\n",
    "import time                       # For handling delays and timing (e.g., cooldowns, pauses)\n",
    "import tempfile                   # For creating temporary files in the system's temp directory\n",
    "import threading                  # For running tasks in parallel (e.g., listening for voice commands while processing video)\n",
    "import pygame                     # For reliable audio playback, replacing less stable libraries\n",
    "\n",
    "# --- System Configuration ---\n",
    "# These are global constants that can be easily tuned\n",
    "\n",
    "ACTIVATION_COMMAND = \"guard my room\"          # Voice command to activate the guard mode\n",
    "DEACTIVATION_COMMAND = \"stand down\"           # Voice command to deactivate the guard mode\n",
    "MODEL_FILE = \"known_faces_model.pkl\"          # Filename for the saved face recognition model\n",
    "\n",
    "# Confidence threshold for face recognition. A face is considered a match only if the\n",
    "# classifier's confidence is above this value. This is a key parameter to tune.\n",
    "RECOGNITION_THRESHOLD = 0.75\n",
    "\n",
    "# --- IMPORTANT: PASTE YOUR GROQ API KEY HERE ---\n",
    "# The API key is required to use the Groq service for the LLM.\n",
    "GROQ_API_KEY = \"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\" # Groq API KEY\n",
    "\n",
    "# --- Global Client Initialization for the LLM ---\n",
    "# Initialize the 'client' variable to None. It will be configured if an API key is provided.\n",
    "client = None\n",
    "try:\n",
    "    # Check if a valid API key has been provided (and is not the placeholder)\n",
    "    if GROQ_API_KEY != \"YOUR_GROQ_API_KEY\" and GROQ_API_KEY:\n",
    "        from groq import Groq                                   # Import the Groq library only if needed\n",
    "        client = Groq(api_key=GROQ_API_KEY)                     # Create the client object to communicate with the Groq API\n",
    "        print(\"[INFO] Groq client configured successfully.\")\n",
    "    else:\n",
    "        print(\"[WARNING] Groq API Key is not set. LLM features will be disabled.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to configure Groq client: {e}\")\n",
    "\n",
    "# --- Base AI Guard Class ---\n",
    "# This class handles the core audio input (ASR) and output (TTS) functionalities.\n",
    "class AI_Guard:\n",
    "    def __init__(self):\n",
    "        self.guard_mode_active = False        # State variable to track if the guard mode is active\n",
    "        self.recognizer = sr.Recognizer()     # Initialize the speech recognizer\n",
    "        self.microphone = sr.Microphone()     # Initialize the microphone\n",
    "        pygame.mixer.init()                   # Initialize the Pygame mixer for reliable audio playback\n",
    "\n",
    "        # Create a threading lock to prevent multiple parts of the program\n",
    "        # from trying to speak at the exact same time, which can cause file access errors.\n",
    "        self.speak_lock = threading.Lock()\n",
    "\n",
    "        print(\"[INFO] AI Guard System Initialized. Calibrating microphone...\")\n",
    "        # Listen for 1 second to adjust the recognizer for ambient noise levels\n",
    "        with self.microphone as source:\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "        print(\"[INFO] Microphone calibrated.\")\n",
    "\n",
    "    def speak(self, text):\n",
    "        \"\"\"Converts text to speech using gTTS and plays it with Pygame.\"\"\"\n",
    "        # Acquire the lock. This ensures that if another thread tries to call speak(),\n",
    "        # it will wait until the current speech is finished.\n",
    "        with self.speak_lock:\n",
    "            print(f\"[GUARD SAYS]: {text}\")\n",
    "            try:\n",
    "                tts = gTTS(text=text, lang='en')                              # Create the gTTS object with the text to be spoken\n",
    "                temp_dir = tempfile.gettempdir()                              # Get the system's temporary directory path to avoid permission errors\n",
    "                audio_file = os.path.join(temp_dir, \"response.mp3\")            # Define the full path for the temporary audio file\n",
    "                tts.save(audio_file)                                           # Save the generated speech to the mp3 file\n",
    "\n",
    "                # Use Pygame's music mixer to play the audio file\n",
    "                pygame.mixer.music.load(audio_file)\n",
    "                pygame.mixer.music.play()\n",
    "                \n",
    "                # Wait in a loop until the audio has finished playing\n",
    "                while pygame.mixer.music.get_busy():\n",
    "                    time.sleep(0.1)\n",
    "                \n",
    "                pygame.mixer.music.unload()   # Unload the file so it can be safely deleted\n",
    "                os.remove(audio_file)        # Remove the temporary audio file\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Could not speak due to an error: {e}\")\n",
    "        # The lock is automatically released here\n",
    "\n",
    "    def listen_for_command(self):\n",
    "        \"\"\"Listens for a command via the microphone and uses Google Web Speech API.\"\"\"\n",
    "        command = \"\"\n",
    "        try:\n",
    "            with self.microphone as source:\n",
    "                print(\"[INFO] Listening for a command...\")\n",
    "                # Listen for up to 5 seconds, stopping after 4 seconds of speech\n",
    "                audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=4)\n",
    "            \n",
    "            print(\"[INFO] Transcribing with Google Speech Recognition...\")\n",
    "            # Use Google's online service to convert the audio to text\n",
    "            command = self.recognizer.recognize_google(audio).lower()\n",
    "            print(f\"[USER SAID]: {command}\")\n",
    "\n",
    "        # Handle common exceptions for speech recognition\n",
    "        except sr.WaitTimeoutError:\n",
    "            pass # This is expected if no one speaks\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"[INFO] Google Speech Recognition could not understand audio.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"[ERROR] Could not request results from Google service; {e}\")\n",
    "        return command\n",
    "\n",
    "# --- Full System Class ---\n",
    "# This class inherits from AI_Guard and adds vision, LLM, and state management.\n",
    "class AI_Guard_Full(AI_Guard):\n",
    "    def __init__(self):\n",
    "        # Initialize the parent AI_Guard class (ASR, TTS, etc.)\n",
    "        super().__init__()\n",
    "        try:\n",
    "            # Load the pre-trained SVM classifier and label encoder\n",
    "            with open(MODEL_FILE, \"rb\") as f:\n",
    "                self.model_data = pickle.load(f)\n",
    "            print(\"[INFO] Loaded trained face recognition model.\")\n",
    "        except FileNotFoundError:\n",
    "            self.speak(f\"Error: Model file '{MODEL_FILE}' not found. Please run enroll_faces.py first.\")\n",
    "            exit()\n",
    "        \n",
    "        # Initialize the webcam (device 0 is usually the built-in one)\n",
    "        self.video_capture = cv2.VideoCapture(0)\n",
    "        if not self.video_capture.isOpened():\n",
    "            self.speak(\"Error: Cannot open webcam.\")\n",
    "            exit()\n",
    "        \n",
    "        # Timestamps to prevent spamming welcome/warning messages\n",
    "        self.last_seen_trusted_time = 0\n",
    "        self.cooldown_period = 10  # 10-second cooldown\n",
    "        # Event to signal the background listener thread to stop\n",
    "        self.stop_event = threading.Event()\n",
    "        # Flag to track if the OpenCV window is currently open\n",
    "        self.vision_window_active = False\n",
    "        # Dictionary to manage the state of an intruder encounter\n",
    "        self.intruder_state = {\"detected\": False, \"start_time\": None, \"escalation_level\": 0, \"last_warning_time\": 0}\n",
    "        # Time intervals (in seconds) for escalating warnings\n",
    "        self.escalation_intervals = {1: 0, 2: 15, 3: 30}\n",
    "\n",
    "    def generate_response(self, level):\n",
    "        \"\"\"Generates a spoken response from the LLM based on the escalation level.\"\"\"\n",
    "        if not client: return \"Language model not available.\"\n",
    "        \n",
    "        # Context-specific prompts for a college hostel environment\n",
    "        system_prompts = {\n",
    "            1: \"You are a friendly AI assistant guarding a college hostel room. In one short, casual sentence, politely ask who they are or if they are looking for the room's resident.\",\n",
    "            2: \"The unrecognized person has not left. Now, adopt a firmer tone. In one short sentence, state that this is a private hostel room and they need to leave.\",\n",
    "            3: \"The intruder is still here. Be very stern and issue a final warning. In one short sentence, state that they are trespassing and that the hostel warden or campus security will be alerted immediately if they don't leave.\"\n",
    "        }\n",
    "        \n",
    "        # Get the appropriate prompt for the current level\n",
    "        prompt_text = system_prompts.get(level, \"An error occurred in security logic.\")\n",
    "        \n",
    "        try:\n",
    "            print(f\"[INFO] Generating Groq response for escalation level {level}...\")\n",
    "            # Send the prompt to the Groq API using the Llama 3.1 model\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt_text}],\n",
    "                model=\"llama-3.1-8b-instant\",\n",
    "                temperature=0.7, max_tokens=50\n",
    "            )\n",
    "            # Extract and return the generated text\n",
    "            return chat_completion.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Groq generation failed: {e}\")\n",
    "            return \"There seems to be an issue with my response circuits.\"\n",
    "\n",
    "    def handle_unrecognized_person(self):\n",
    "        \"\"\"Manages the state and logic for an escalating encounter with an intruder.\"\"\"\n",
    "        current_time = time.time()\n",
    "        # If this is the first time seeing an intruder\n",
    "        if not self.intruder_state[\"detected\"]:\n",
    "            print(\"[ALERT] Intruder detected for the first time.\")\n",
    "            # Update the state to start the encounter\n",
    "            self.intruder_state.update({\"detected\": True, \"start_time\": current_time, \"escalation_level\": 1, \"last_warning_time\": current_time})\n",
    "            # Generate and speak the Level 1 warning\n",
    "            response = self.generate_response(1)\n",
    "            self.speak(response)\n",
    "            return\n",
    "        \n",
    "        # Calculate how long the intruder has been present\n",
    "        time_since_detection = current_time - self.intruder_state[\"start_time\"]\n",
    "        new_level = 0\n",
    "        # Determine if it's time to escalate to the next warning level\n",
    "        if time_since_detection > self.escalation_intervals[3] and self.intruder_state[\"escalation_level\"] < 3:\n",
    "            new_level = 3\n",
    "        elif time_since_detection > self.escalation_intervals[2] and self.intruder_state[\"escalation_level\"] < 2:\n",
    "            new_level = 2\n",
    "        \n",
    "        # If a new escalation level has been reached\n",
    "        if new_level > self.intruder_state[\"escalation_level\"]:\n",
    "            print(f\"[ALERT] Escalating to level {new_level}.\")\n",
    "            self.intruder_state.update({\"escalation_level\": new_level, \"last_warning_time\": current_time})\n",
    "            response = self.generate_response(new_level)\n",
    "            self.speak(response)\n",
    "\n",
    "    def reset_intruder_state(self):\n",
    "        \"\"\"Resets the intruder encounter state back to default.\"\"\"\n",
    "        if self.intruder_state[\"detected\"]:\n",
    "            print(\"[INFO] Threat cleared. Resetting intruder state.\")\n",
    "            self.intruder_state = {\"detected\": False, \"start_time\": None, \"escalation_level\": 0, \"last_warning_time\": 0}\n",
    "\n",
    "    def process_vision(self):\n",
    "        \"\"\"The main computer vision loop: captures frame, finds faces, and identifies them.\"\"\"\n",
    "        ret, frame = self.video_capture.read()\n",
    "        if not ret: return\n",
    "        \n",
    "        # Create a smaller version of the frame for faster face recognition\n",
    "        rgb_small_frame = cv2.cvtColor(cv2.resize(frame, (0, 0), fx=0.25, fy=0.25), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find all faces and their encodings in the small frame\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        is_trusted_person_present = False\n",
    "        is_any_person_present = len(face_encodings) > 0\n",
    "        classifier = self.model_data[\"classifier\"]\n",
    "        label_encoder = self.model_data[\"label_encoder\"]\n",
    "\n",
    "        # Loop through each detected face\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Use the trained SVM classifier to get prediction probabilities\n",
    "            probabilities = classifier.predict_proba([face_encoding])[0]\n",
    "            best_match_index = np.argmax(probabilities)\n",
    "            predicted_name = label_encoder.classes_[best_match_index]\n",
    "            confidence = probabilities[best_match_index]\n",
    "            \n",
    "            print(f\"[DEBUG] Predicted: {predicted_name}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "            display_name = \"Unrecognized\"\n",
    "            # If the confidence is above our threshold, we have a match\n",
    "            if confidence > RECOGNITION_THRESHOLD:\n",
    "                is_trusted_person_present = True\n",
    "                display_name = predicted_name.replace('_', ' ')\n",
    "                self.reset_intruder_state() # A trusted person is here, so the threat is cleared\n",
    "                \n",
    "                current_time = time.time()\n",
    "                # Greet the trusted person if enough time has passed since the last greeting\n",
    "                if current_time - self.last_seen_trusted_time > self.cooldown_period:\n",
    "                    self.speak(f\"Welcome back, {display_name}.\")\n",
    "                    self.last_seen_trusted_time = current_time\n",
    "            \n",
    "            # --- Visual Feedback on the Pop-up Window ---\n",
    "            top *= 4; right *= 4; bottom *= 4; left *= 4                                 # Scale face locations back up to the original frame size\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)              # Draw a green box around the face\n",
    "            label = f\"{display_name} ({confidence:.2f})\"                                        # Create the text label with the name and confidence score\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)     # Draw a filled rectangle as a background for the label\n",
    "            cv2.putText(frame, label, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 1)     # Draw the text label on the frame\n",
    "\n",
    "        # Logic to handle an unrecognized person\n",
    "        if not is_trusted_person_present and is_any_person_present:\n",
    "            self.handle_unrecognized_person()\n",
    "        # Logic to reset the intruder state if everyone leaves\n",
    "        elif not is_any_person_present:\n",
    "            if self.intruder_state[\"detected\"]:\n",
    "                self.reset_intruder_state()\n",
    "        \n",
    "        # Display the resulting frame in a pop-up window\n",
    "        cv2.imshow('AI Guard System', frame)\n",
    "        self.vision_window_active = True\n",
    "\n",
    "    def _threaded_listener(self):\n",
    "        \"\"\"This function runs in a separate thread, dedicated to listening for voice commands.\"\"\"\n",
    "        # This loop runs continuously in the background\n",
    "        while not self.stop_event.is_set():\n",
    "            # Listen for a single command\n",
    "            command = self.listen_for_command()\n",
    "\n",
    "            # Process the command\n",
    "            if ACTIVATION_COMMAND in command and not self.guard_mode_active:\n",
    "                self.guard_mode_active = True\n",
    "                self.speak(\"Guard mode activated. Monitoring the room.\")\n",
    "            elif DEACTIVATION_COMMAND in command and self.guard_mode_active:\n",
    "                self.guard_mode_active = False\n",
    "                self.speak(\"Guard mode deactivated.\")\n",
    "                self.reset_intruder_state()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"The main application entry point.\"\"\"\n",
    "        self.stop_event.clear()\n",
    "        # Create and start the background listener thread\n",
    "        listener_thread = threading.Thread(target=self._threaded_listener, daemon=True)\n",
    "        listener_thread.start()\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\n[INFO] AI Guard is running. Say '{ACTIVATION_COMMAND}' to activate.\")\n",
    "            # The main loop now primarily handles vision processing and window management\n",
    "            while not self.stop_event.is_set():\n",
    "                if self.guard_mode_active:\n",
    "                    self.process_vision()\n",
    "                else:\n",
    "                    # If idle, ensure the vision window is closed\n",
    "                    if self.vision_window_active:\n",
    "                        cv2.destroyWindow('AI Guard System')\n",
    "                        self.vision_window_active = False\n",
    "                \n",
    "                # Check if the 'q' key was pressed in the OpenCV window to quit\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    print(\"\\n[INFO] 'q' key pressed. Shutting down.\")\n",
    "                    break\n",
    "                \n",
    "                # Sleep to manage CPU usage. Short sleep when active, longer when idle.\n",
    "                time.sleep(0.05 if self.guard_mode_active else 0.5)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n[INFO] Program interrupted by user. Shutting down.\")\n",
    "        finally:\n",
    "            # --- Graceful Shutdown ---\n",
    "            self.stop_event.set()   # Signal all threads to stop\n",
    "            listener_thread.join(timeout=1.0)    # Wait for the listener thread to finish\n",
    "            self.video_capture.release()       # Release the webcam\n",
    "            cv2.destroyAllWindows()       # Close all OpenCV windows\n",
    "            pygame.mixer.quit()\n",
    "            print(\"[INFO] System resources released. Shutdown complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    guard = AI_Guard_Full()\n",
    "    guard.run()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
